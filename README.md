# LGF-SLR
## Abstract
For those who are deaf, sign language recognition (SLR) technology can offer a more practical and effective means of communication. A skeleton-based sign language recognition system has gained popularity and been used in real-world scenarios because of its benefits in generalization, computing efficiency, anti-interference, and privacy protection. Unfortunately, this method's low recognition rate is frequently caused by inadequate hand-skeletal information. In order to recognize sign language, the multi-stream fusion technique is also frequently employed; however, this approach frequently uses human weight assignment, which has drawbacks including subjectivity and inefficiency. This research offers a Hand Local-Global Fusion Network for Skeleton-Based Sign Language Recognition (LGF-SLR), based on the aforementioned difficulties. To the greatest extent possible, the skeleton information is preserved while it is extracted and inputted into the network's global feature streams (upper body) and local feature streams (left and right hands) independently. Simultaneously, the multi-stream fusion component introduces Bayesian optimization, which automatically gives weights to different prediction knots and lessens the impact of manually assigned weights on the trial outcomes. Lastly, the AUTSL sign language recognition dataset, the WLASL American Sign Language dataset, and the CSL Chinese sign language dataset are used to assess the LGF-SLR framework. The results show that the accuracy of the framework is higher than the state-of-the-art, with accuracies of 95.93%, 52.74%, and x%, respectively.
## Table of Contents
*Data Preparation
*Requirements
*Pretrained Models
*Usage
